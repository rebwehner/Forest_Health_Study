{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8703d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d5d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules needed for processing \n",
    "\n",
    "import sentinelsat\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentinelsat\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baffbca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Rebekah\\anaconda3\\envs\\sia\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1s             |       hcfcfb64_0         5.9 MB  conda-forge\n",
      "    pandas-1.5.2               |   py39h2ba5b7c_0         9.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        15.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                 1.1.1q-hcfcfb64_1 --> 1.1.1s-hcfcfb64_0\n",
      "  pandas                               1.5.0-py39h2ba5b7c_0 --> 1.5.2-py39h2ba5b7c_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "openssl-1.1.1s       | 5.9 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.9 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.9 MB    | #5         |  15% \n",
      "openssl-1.1.1s       | 5.9 MB    | ###4       |  35% \n",
      "openssl-1.1.1s       | 5.9 MB    | #####5     |  55% \n",
      "openssl-1.1.1s       | 5.9 MB    | ########5  |  85% \n",
      "openssl-1.1.1s       | 5.9 MB    | ########## | 100% \n",
      "\n",
      "pandas-1.5.2         | 9.1 MB    |            |   0% \n",
      "pandas-1.5.2         | 9.1 MB    | #1         |  11% \n",
      "pandas-1.5.2         | 9.1 MB    | ###2       |  33% \n",
      "pandas-1.5.2         | 9.1 MB    | #####4     |  55% \n",
      "pandas-1.5.2         | 9.1 MB    | #######9   |  80% \n",
      "pandas-1.5.2         | 9.1 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.14.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475b3285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentinelsat in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: html2text in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2020.1.16)\n",
      "Requirement already satisfied: tqdm>=4.58 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (4.64.1)\n",
      "Requirement already satisfied: geomet in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (0.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2.28.1)\n",
      "Requirement already satisfied: geojson>=2 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2.5.0)\n",
      "Requirement already satisfied: click>=7.1 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from click>=7.1->sentinelsat) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from geomet->sentinelsat) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rebekah\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install sentinelsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0514e9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentinelsat.sentinel.SentinelAPI at 0x2707fc14bb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credentials for api\n",
    "api = SentinelAPI(\n",
    "    'rwehner', \n",
    "    'Sia416fall22', \n",
    "    'https://apihub.copernicus.eu/apihub'\n",
    ")\n",
    "\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0951fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson that includes Kakamega Forest National Reserve, Ethiopia\n",
    "kf_geometry = {\n",
    "  \"type\": \"Polygon\",\n",
    "  \"coordinates\": [\n",
    "    [ \n",
    "      [34.85042675684193, 0.32277955006604486],\n",
    "      [34.85042675684193, 0.25648957869283606],\n",
    "      [34.91638107726757, 0.25648957869283606],\n",
    "      [34.91638107726757, 0.32277955006604486],\n",
    "      [34.85042675684193, 0.32277955006604486]\n",
    "    ]\n",
    "  ]\n",
    "}\n",
    "\n",
    "# convert geojson into well-known-text so that the api can be queried\n",
    "kf_footprint = geojson_to_wkt(kf_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2c864fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON((34.8504 0.3228,34.8504 0.2565,34.9164 0.2565,34.9164 0.3228,34.8504 0.3228))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credentials for api\n",
    "api = SentinelAPI(\n",
    "    'rwehner', \n",
    "    'Sia416fall22', \n",
    "    'https://apihub.copernicus.eu/apihub'\n",
    ")\n",
    "\n",
    "'https://apihub.copernicus.eu/apihub'\n",
    "\n",
    "# geojson that includes Kakamega Forest National Reserve, Ethiopia\n",
    "kf_geometry = {\n",
    "  \"type\": \"Polygon\",\n",
    "  \"coordinates\": [\n",
    "    [ \n",
    "      [34.85042675684193, 0.32277955006604486],\n",
    "      [34.85042675684193, 0.25648957869283606],\n",
    "      [34.91638107726757, 0.25648957869283606],\n",
    "      [34.91638107726757, 0.32277955006604486],\n",
    "      [34.85042675684193, 0.32277955006604486]\n",
    "    ]\n",
    "  ]\n",
    "}\n",
    "\n",
    "# convert geojson into well-known-text so that the api can be queried\n",
    "kf_footprint = geojson_to_wkt(kf_geometry)\n",
    "kf_footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83990f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the query for the api\n",
    "kf22_11_metadata = api.query(\n",
    "    kf_footprint,\n",
    "    date=('20221101', '20221124'), # date range November 2022\n",
    "    platformname='Sentinel-2',  \n",
    "    processinglevel='Level-2A' # image is processed for surface reflection (not Level-1C top of atmosphere)\n",
    ")\n",
    "\n",
    "kf22_11_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bab84729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf22_11_df = api.to_dataframe(kf22_11_metadata)\n",
    "kf22_11_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b8c7b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf22_11_metadata_df = api.to_dataframe(kf22_11_metadata)\n",
    "kf22_11_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sat_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf22_11_metadata_df = api.to_dataframe(kf22_11_metadata)\n",
    "kf22_11_metadata_df.to_csv('kf22_11_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3635dcbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cloudcoverpercentage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m kf_metadata_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkf_metadata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# sorting the data frame to have the clouds with the least cloud cover at the top of the list\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m kf_metadata_df_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mkf_metadata_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcloudcoverpercentage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m kf_metadata_df_sorted\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkf_metadata_sorted.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)    \u001b[38;5;66;03m# printing to csv to inspect metadata\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# create a subset of images with the least cloud \u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\core\\frame.py:6904\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6900\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[0;32m   6901\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6903\u001b[0m     by \u001b[38;5;241m=\u001b[39m by[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 6904\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6906\u001b[0m     \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6908\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6909\u001b[0m         \u001b[38;5;66;03m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\core\\generic.py:1849\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1843\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1844\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1847\u001b[0m     )\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1849\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cloudcoverpercentage'"
     ]
    }
   ],
   "source": [
    "# build the query for the api\n",
    "kf_metadata = api.query(\n",
    "    kf_footprint,\n",
    "    date=('20221001', '20221031'), # date range Oct 2022\n",
    "    platformname='Sentinel-2',  \n",
    "    processinglevel='Level-2A' # image is processed for surface reflection (not Level-1C top of atmosphere)\n",
    ")\n",
    "\n",
    "kf_metadata_df = api.to_dataframe(kf_metadata)\n",
    "kf_metadata_df.to_csv('kf_metadata.csv')\n",
    "\n",
    "# sorting the data frame to have the clouds with the least cloud cover at the top of the list\n",
    "kf_metadata_df_sorted = kf_metadata_df.sort_values(\n",
    "    ['cloudcoverpercentage'], ascending=[True])\n",
    "\n",
    "kf_metadata_df_sorted.to_csv('kf_metadata_sorted.csv')    # printing to csv to inspect metadata\n",
    "\n",
    "# create a subset of images with the least cloud \n",
    "kf_metadata_df_sorted_top = kf_metadata_df_sorted.head(1)\n",
    "len(kf_metadata_df_sorted_top)    #double checking how many images are in subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2c87f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbab61a202549a39759a6aaff9a8002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading products:   0%|          | 0/1 [00:00<?, ?product/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3ace962d2c45c78596ba8e77d42cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading S2A_MSIL2A_20221023T075001_N0400_R135_T36NYF_20221023T111454.zip:   0%|          | 0.00/1.20G [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MD5 checksumming:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResultTuple(downloaded={'e15c9855-332d-4904-90e1-6143af4d6448': {'id': 'e15c9855-332d-4904-90e1-6143af4d6448', 'title': 'S2A_MSIL2A_20221023T075001_N0400_R135_T36NYF_20221023T111454', 'size': 1196118109, 'md5': '679d5ceacad2ca40d7bc9e03554c2373', 'date': datetime.datetime(2022, 10, 23, 7, 50, 1, 24000), 'footprint': 'POLYGON((34.79691598168977 0.904463645229748,35.78297722553378 0.903837296874274,35.782636294845624 -0.08837769347984,34.7966956471426 -0.088438933321785,34.79691598168977 0.904463645229748))', 'url': \"https://apihub.copernicus.eu/apihub/odata/v1/Products('e15c9855-332d-4904-90e1-6143af4d6448')/$value\", 'Online': True, 'Creation Date': datetime.datetime(2022, 10, 23, 13, 20, 9, 552000), 'Ingestion Date': datetime.datetime(2022, 10, 23, 13, 19, 49, 354000), 'quicklook_url': \"https://apihub.copernicus.eu/apihub/odata/v1/Products('e15c9855-332d-4904-90e1-6143af4d6448')/Products('Quicklook')/$value\", 'path': 'S2A_MSIL2A_20221023T075001_N0400_R135_T36NYF_20221023T111454.zip', 'downloaded_bytes': 1196118109}}, retrieval_triggered={}, failed={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download images with the least cloud cover\n",
    "api.download_all(kf_metadata_df_sorted_top.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2886ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0bf7e7fe924d3eb9a9d2d1adf96838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading S2B_MSIL2A_20221028T075009_N0400_R135_T37NBH_20221028T100913.zip:   0%|          | 0.00/1.17G [00:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MD5 checksumming:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '6cbb51f8-bcf1-4da7-9079-a1cf2e6d0250',\n",
       " 'title': 'S2B_MSIL2A_20221028T075009_N0400_R135_T37NBH_20221028T100913',\n",
       " 'size': 1174245720,\n",
       " 'md5': '35af98a06e92997f528b9a6ec6bcafe5',\n",
       " 'date': datetime.datetime(2022, 10, 28, 7, 50, 9, 24000),\n",
       " 'footprint': 'POLYGON((36.28332509808656 7.22972573268273,37.277167102798245 7.234568851431087,37.28066847700756 6.241762371609503,36.28884136086616 6.23758935706673,36.28332509808656 7.22972573268273))',\n",
       " 'url': \"https://apihub.copernicus.eu/apihub/odata/v1/Products('6cbb51f8-bcf1-4da7-9079-a1cf2e6d0250')/$value\",\n",
       " 'Online': True,\n",
       " 'Creation Date': datetime.datetime(2022, 10, 28, 17, 36, 1, 835000),\n",
       " 'Ingestion Date': datetime.datetime(2022, 10, 28, 17, 35, 21, 648000),\n",
       " 'quicklook_url': \"https://apihub.copernicus.eu/apihub/odata/v1/Products('6cbb51f8-bcf1-4da7-9079-a1cf2e6d0250')/Products('Quicklook')/$value\",\n",
       " 'path': 'S2B_MSIL2A_20221028T075009_N0400_R135_T37NBH_20221028T100913.zip',\n",
       " 'downloaded_bytes': 1174245720}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.download(omo_metadata_df_sorted.index[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89155c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management of downloaded zips\n",
    "# find the downloaded file names, create a list, and add the only the zip files using a loop\n",
    "all_filenames_in_folder = os.listdir()\n",
    "kf_filenames_to_unzip = []\n",
    "for filename in all_filenames_in_folder:\n",
    "    if filename.endswith('.zip'): \n",
    "        kf_filenames_to_unzip.append(filename)\n",
    "        \n",
    "# Create a folder for the images and add the unzipped files, remove the zip for a clean workspace\n",
    "kf_folder = 'kakamega_unzipped'\n",
    "if not os.path.exists(kf_folder):\n",
    "    os.mkdir(kf_folder)    #create the folder\n",
    "for filename in kf_filenames_to_unzip:\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(kf_folder)\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df0b8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:32636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'Polygon',\n",
       "  'coordinates': [[[705938.9657709773, 35695.58166733245],\n",
       "    [705940.1630230347, 28364.69776423637],\n",
       "    [713283.1483790588, 28365.77869749741],\n",
       "    [713281.9083744495, 35696.94195823307],\n",
       "    [705938.9657709773, 35695.58166733245]]]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify filename and assign as a rasterio object\n",
    "kf_file = \"T36NYF_20221023T075001_TCI_10m.jp2\"\n",
    "kf_ro = rasterio.open(omo_file)\n",
    "\n",
    "# define AOI with geojson of Harrisburg, PA\n",
    "print(kf_ro.crs)\n",
    "\n",
    "# define boundary for clipping AoI converting to UTM with epsg.io\n",
    "kf_aoi_geometry = [{\n",
    "  \"type\": \"Polygon\",\n",
    "  \"coordinates\": [\n",
    "    [ \n",
    "      [705938.9657709773, 35695.58166733245],\n",
    "      [705940.1630230347, 28364.69776423637],\n",
    "      [713283.1483790588, 28365.77869749741],\n",
    "      [713281.9083744495, 35696.94195823307],\n",
    "      [705938.9657709773, 35695.58166733245]\n",
    "    ]\n",
    "  ]\n",
    "}]\n",
    "kf_aoi_geometry    #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420708a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "upscale_factor = 2\n",
    "\n",
    "# load band 05 from a sentinel2 footprint\n",
    "# this is 20m resolution I one an output raster of 10m resolution\n",
    "with rasterio.open(\"images/B05.jp2\", driver='JP2OpenJPEG') as dataset:\n",
    "\n",
    "    # resample data to target shape\n",
    "    data = dataset.read(\n",
    "        out_shape=(\n",
    "            dataset.count,\n",
    "            int(dataset.height * upscale_factor),\n",
    "            int(dataset.width * upscale_factor)\n",
    "        ),\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "    # scale image transform\n",
    "    transform = dataset.transform * dataset.transform.scale(\n",
    "        (dataset.width / data.shape[-1]),\n",
    "        (dataset.height / data.shape[-2])\n",
    "    )\n",
    "\n",
    "    \n",
    "    #Finally I want export image.. save in the disk with crs geotiff\n",
    "    #...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2358d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasterio.enums import Resampling\n",
    "# https://rasterio.readthedocs.io/en/latest/api/rasterio.enums.html#rasterio.enums.Resampling\n",
    "\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "upscale_factor = 2   #Downsampling to 1/2 of the resolution can be done with upscale_factor = 1/2\n",
    "\n",
    "with rasterio.open(\"example.tif\") as dataset:\n",
    "\n",
    "    # resample data to target shape\n",
    "    data = dataset.read(\n",
    "        out_shape=(\n",
    "            dataset.count,\n",
    "            int(dataset.height * upscale_factor),\n",
    "            int(dataset.width * upscale_factor)\n",
    "        ),\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "    # scale image transform\n",
    "    transform = dataset.transform * dataset.transform.scale(\n",
    "        (dataset.width / data.shape[-1]),\n",
    "        (dataset.height / data.shape[-2])\n",
    "    )\n",
    "    \n",
    "    import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "with rasterio.open(\"example.tif\") as dataset:\n",
    "\n",
    "    # resample data to target shape\n",
    "    data = dataset.read(\n",
    "        out_shape=(\n",
    "            dataset.count,\n",
    "            new_height,\n",
    "            new_width\n",
    "        ),\n",
    "        resampling=Resampling.bilinear #you can also use nearest or bicubic if you want\n",
    "    )\n",
    "\n",
    "    # scale image transform\n",
    "    transform = dataset.transform * dataset.transform.scale(\n",
    "        (dataset.width / data.shape[-1]),\n",
    "        (dataset.height / data.shape[-2])\n",
    "    )\n",
    "    \n",
    "#https://gis.stackexchange.com/questions/407613/resampling-sentinel-2-bands-reduce-resolution-10m-to-20m-resolution-in-google\n",
    "    \n",
    "    var resample20 = function(image){\n",
    "  var projection =image.select('B12').projection();\n",
    "  var bands = image.select('B[2-4]','B8','B8A','B11','B12');\n",
    "  var resample = bands.reproject({\n",
    "      crs: projection,\n",
    "      scale: 20\n",
    "    });\n",
    "     return resample \n",
    "  .copyProperties(image,['system:time_start','system:time_end']);\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55870b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gis.stackexchange.com/questions/341809/merging-sentinel-2-rgb-bands-with-rasterio#355077\n",
    "import numpy as np\n",
    "from rasterio import plot\n",
    "from rasterio.plot import show\n",
    "\n",
    "band2=rasterio.open(\"B02.jp2\")\n",
    "band3=rasterio.open(\"B03.jp2\")\n",
    "band4=rasterio.open(\"B04.jp2\")\n",
    "\n",
    "rgb=rasterio.open('rgb.tiff', 'w', driver='Gtiff',\n",
    "                          width=band2.width, height=band2.height,\n",
    "                          count=3,\n",
    "                          crs=band2.crs,\n",
    "                          transform=band2.transform,\n",
    "                          dtype='uint16')\n",
    "rgb.write(band4.read(1),1)\n",
    "rgb.write(band3.read(1),2)\n",
    "rgb.write(band2.read(1),3)\n",
    "rgb.close()\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import plot\n",
    "from rasterio.plot import show\n",
    "from skimage import exposure\n",
    "\n",
    "band2=rasterio.open(\"B02.jp2\")\n",
    "band3=rasterio.open(\"B03.jp2\")\n",
    "band4=rasterio.open(\"B04.jp2\")\n",
    "\n",
    "band2_geo = band2.profile\n",
    "band2_geo.update({\"count\": 3})\n",
    "\n",
    "with rasterio.open('rgb.tiff', 'w', **band2_geo) as dest:\n",
    "# I rearanged the band order writting to 2→3→4 instead of 4→3→2\n",
    "    dest.write(band2.read(1),1)\n",
    "    dest.write(band3.read(1),2)\n",
    "    dest.write(band4.read(1),3)\n",
    "\n",
    "# Rescale the image (divide by 10000 to convert to [0:1] reflectance\n",
    "img = rasterio.open('rgb.tiff')\n",
    "image = np.array([img.read(3), img.read(2), img.read(1)]).transpose(1,2,0)\n",
    "p2, p98 = np.percentile(image, (2,98))\n",
    "image = exposure.rescale_intensity(image, in_range=(p2, p98)) / 100000\n",
    "\n",
    "# Plot the RGB image\n",
    "show(image.transpose(2,0,1), transform=img.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26813cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'JP2OpenJPEG', 'dtype': 'uint8', 'nodata': None, 'width': 736, 'height': 734, 'count': 3, 'crs': CRS.from_epsg(32636), 'transform': Affine(10.0, 0.0, 705930.0,\n",
      "       0.0, -10.0, 35700.0)}\n",
      "Writing complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clip image using mask from rasterio\n",
    "with rasterio.open(kf_file) as kf_img:\n",
    "    kf_clipped, transform = mask(kf_img, kf_aoi_geometry, crop=True)\n",
    "\n",
    "# add metadata to new clipped image by copying orginal metadata, then write new GeoTiff\n",
    "kf_meta = kf_ro.meta.copy()\n",
    "kf_meta.update(\n",
    "    {\n",
    "    \n",
    "        \"transform\": transform,\n",
    "        \"height\":kf_clipped.shape[1],\n",
    "        \"width\":kf_clipped.shape[2]\n",
    "    }\n",
    ")\n",
    "print(kf_meta)    # double check \n",
    "with rasterio.open('kf_clipped.tif', 'w', **kf_meta) as my_writer_object:\n",
    "    my_writer_object.write(kf_clipped)\n",
    "    \n",
    "print('Writing complete')    # know when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7777676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the API\n",
    "#from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "#from datetime import date\n",
    "\n",
    "#api = SentinelAPI('user', 'password', 'https://apihub.copernicus.eu/apihub')\n",
    "\n",
    "# download single scene by known product id\n",
    "#api.download(<product_id>)\n",
    "\n",
    "# search by polygon, time, and SciHub query keywords\n",
    "#footprint = geojson_to_wkt(read_geojson('/path/to/map.geojson'))\n",
    "#products = api.query(footprint,\n",
    "#                     date=('20151219', date(2015, 12, 29)),\n",
    "#                     platformname='Sentinel-2',\n",
    "#                     cloudcoverpercentage=(0, 30))\n",
    "\n",
    "# download all results from the search\n",
    "#api.download_all(products)\n",
    "\n",
    "# convert to Pandas DataFrame\n",
    "#products_df = api.to_dataframe(products)\n",
    "\n",
    "# GeoJSON FeatureCollection containing footprints and metadata of the scenes\n",
    "#api.to_geojson(products)\n",
    "\n",
    "# GeoPandas GeoDataFrame with the metadata of the scenes and the footprints as geometries\n",
    "#api.to_geodataframe(products)\n",
    "\n",
    "# Get basic information about the product: its title, file size, MD5 sum, date, footprint and\n",
    "# its download url\n",
    "#api.get_product_odata(<product_id>)\n",
    "\n",
    "# Get the product's full metadata available on the server\n",
    "#api.get_product_odata(<product_id>, full=True)\n",
    "\n",
    "# connect to the API\n",
    "#from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "#from datetime import date\n",
    "\n",
    "#api = SentinelAPI('user', 'password', 'https://apihub.copernicus.eu/apihub')\n",
    "\n",
    "# search by polygon, time, and SciHub query keywords\n",
    "#footprint = geojson_to_wkt(read_geojson('map.geojson'))\n",
    "#products = api.query(footprint,\n",
    "#                     date=('20151219', date(2015, 12, 29)),\n",
    "#                     platformname='Sentinel-2')\n",
    "\n",
    "# convert to Pandas DataFrame\n",
    "#products_df = api.to_dataframe(products)\n",
    "\n",
    "# sort and limit to first 5 sorted products\n",
    "#products_df_sorted = products_df.sort_values(['cloudcoverpercentage', 'ingestiondate'], ascending=[True, True])\n",
    "#products_df_sorted = products_df_sorted.head(5)\n",
    "\n",
    "# download sorted and reduced products\n",
    "#api.download_all(products_df_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify filename and assign as a rasterio object\n",
    "kf_file = \"T36NYF_20221023T075001_TCI_10m.jp2\"\n",
    "kf_ro = rasterio.open(omo_file)\n",
    "\n",
    "# define AOI with geojson of Harrisburg, PA\n",
    "print(kf_ro.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eeeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  \n",
    "\n",
    "bin_number = 200\n",
    "\n",
    "ax.hist(gndvi1_w, color='darkblue', bins=bin_number, alpha=0.7)\n",
    "ax.hist(gndvi2_x, color='mediumblue', bins=bin_number, alpha=0.7)\n",
    "ax.hist(gndvi3_y,  color='royalblue', bins=bin_number, alpha=0.7)\n",
    "ax.hist(gndvi4_z, color='cornflowerblue', bins=bin_number, alpha=0.7)\n",
    "ax.hist(gndvi4_zz, color='lightblue', bins=bin_number, alpha=0.7)\n",
    "\n",
    "ax.set_title('GNDVI Kakamega Forest 2019-2022')\n",
    "ax.set_xlabel('Green Normalized Difference Vegetation Index (GNDVI)')\n",
    "ax.set_ylabel('Pixel Frequency')\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "import matplotlib.patches as mpat\n",
    "\n",
    "handle1 = mpat.Patch(color='darkblue', label='5/17/2019')\n",
    "handle2 = mpat.Patch(color='mediumblue', label='6/25/2020')\n",
    "handle3 = mpat.Patch(color='royalblue', label='6/5/2021')\n",
    "handle4 = mpat.Patch(color='cornflowerblue', label='6/15/2022')\n",
    "handle5 = mpat.Patch(color='lightblue', label='5/16/2022')\n",
    "ax.legend(handles=[handle1, handle2, handle3, handle4, handle5])\n",
    "\n",
    "fig.savefig(\"gndvi_time_series.png\", dpi=300, bbox_inches='tight', pad_inches=0.7, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "# get data\n",
    "gndvi1_w = gndvi_w[np.not_equal(gndvi_w, w1_ro.nodata)]\n",
    "gndvi2_x = gndvi_x[np.not_equal(gndvi_x, x1_ro.nodata)]\n",
    "gndvi3_y = gndvi_y[np.not_equal(gndvi_y, y1_ro.nodata)]\n",
    "gndvi4_z = gndvi_z[np.not_equal(gndvi_z, z1_ro.nodata)]\n",
    "gndvi4_zz = gndvi_zz[np.not_equal(gndvi_zz, z1_ro.nodata)]\n",
    "\n",
    "# create the histogram\n",
    "ax1[0].hist(gndvi1_w, bins=100, color='darkblue')\n",
    "ax1[1].hist(gndvi2_x, bins=100, color='mediumblue')\n",
    "ax2[0].hist(gndvi3_y, bins=100, color='royalblue')\n",
    "ax2[1].hist(gndvi4_z, bins=100, color='cornflowerblue')\n",
    "\n",
    "# add plot titles \n",
    "ax1[0].set_title('GNDVI 5/17/19')\n",
    "ax1[1].set_title('GNDVI 6/25/20')\n",
    "ax2[0].set_title('GNDVI 6/5/21')\n",
    "ax2[1].set_title('GNDVI 6/15/22')\n",
    "\n",
    "# sufficient space between our plots\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"gndvi_histograms.png\", dpi=300, bbox_inches='tight', pad_inches=0.7, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4370de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNDVI green normalized difference vegetation index\n",
    "np.seterr(divide='ignore', invalid='ignore') #ignores warning of dividing by zero\n",
    "\n",
    "gndvi_w = (B08_w.astype(float)-B03_w.astype(float))/(B08_w.astype(float)+B03_w.astype(float))\n",
    "gndvi_x = (B08_x.astype(float)-B03_x.astype(float))/(B08_x.astype(float)+B03_x.astype(float))\n",
    "gndvi_y = (B08_y.astype(float)-B03_y.astype(float))/(B08_y.astype(float)+B03_y.astype(float))\n",
    "gndvi_z = (B08_z.astype(float)-B03_z.astype(float))/(B08_z.astype(float)+B03_z.astype(float))\n",
    "gndvi_zz = (B08_zz.astype(float)-B03_zz.astype(float))/(B08_zz.astype(float)+B03_zz.astype(float))\n",
    "\n",
    "print('\\nMax GNDVI 5/17/19: {m}'.format(m=gndvi_w.max()))\n",
    "print('Mean GNDVI 5/17/19: {m}'.format(m=gndvi_w.mean()))\n",
    "print('Median GNDVI 5/17/19: {m}'.format(m=np.median(gndvi_w)))\n",
    "print('Min GNDVI 5/17/19: {m}'.format(m=gndvi_w.min()))\n",
    "\n",
    "print('\\nMax GNDVI 6/25/21: {m}'.format(m=gndvi_x.max()))\n",
    "print('Mean GNDVI 6/25/21: {m}'.format(m=gndvi_x.mean()))\n",
    "print('Median GNDVI 6/25/21: {m}'.format(m=np.median(gndvi_x)))\n",
    "print('Min GNDVI 6/25/21: {m}'.format(m=gndvi_x.min()))\n",
    "\n",
    "print('\\nMax GNDVI 6/05/21: {m}'.format(m=gndvi_y.max()))\n",
    "print('Mean GNDVI 6/05/21: {m}'.format(m=gndvi_y.mean()))\n",
    "print('Median GNDVI 6/05/21: {m}'.format(m=np.median(gndvi_y)))\n",
    "print('Min GNDVI 6/05/21: {m}'.format(m=gndvi_y.min()))\n",
    "\n",
    "print('\\nMax GNDVI 6/15/22: {m}'.format(m=gndvi_z.max()))\n",
    "print('Mean GNDVI 6/15/22: {m}'.format(m=gndvi_z.mean()))\n",
    "print('Median GNDVI 6/15/22: {m}'.format(m=np.median(gndvi_z)))\n",
    "print('Min GNDVI 6/15/22: {m}'.format(m=gndvi_z.min()))\n",
    "\n",
    "print('\\nMax GNDVI 5/16/22: {m}'.format(m=gndvi_zz.max()))\n",
    "print('Mean GNDVI 5/16/22: {m}'.format(m=gndvi_zz.mean()))\n",
    "print('Median GNDVI 5/16/22: {m}'.format(m=np.median(gndvi_zz)))\n",
    "print('Min GNDVI 5/16/22: {m}'.format(m=gndvi_zz.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal, gdalnumeric\n",
    "import numpy as np\n",
    "\n",
    "# \"Before\" image\n",
    "im1 = \"before.tif\"\n",
    "# \"After\" image\n",
    "im2 = \"after.tif\"\n",
    "# Load before and after into arrays\n",
    "ar1 = gdalnumeric.LoadFile(im1).astype(np.int8)\n",
    "ar2 = gdalnumeric.LoadFile(im2)[1].astype(np.int8)\n",
    "# Perform a simple array difference on the images\n",
    "diff = ar2 - ar1\n",
    "# Set up our classification scheme to try\n",
    "# and isolate significant changes\n",
    "classes = np.histogram(diff, bins=5)[1]\n",
    "# The color black is repeated to mask insignificant changes\n",
    "lut = [[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,255,0],[255,0,0]]\n",
    "# Starting value for classification\n",
    "start = 1\n",
    "# Set up the output image\n",
    "rgb = np.zeros((3, diff.shape[0], diff.shape[1],), np.int8)\n",
    "# Process all classes and assign colors\n",
    "for i in range(len(classes)):\n",
    "    mask = np.logical_and(start <= diff, diff <= classes[i])\n",
    "    for j in range(len(lut[i])):\n",
    "        rgb[j] = np.choose(mask, (rgb[j], lut[i][j]))\n",
    "    start = classes[i]+1\n",
    "# Save the output image\n",
    "gdalnumeric.SaveArray(rgb, \"change.tif\", format=\"GTiff\",\\ prototype=im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a query object\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': time,\n",
    "    'measurements': ['red',\n",
    "                     'green',\n",
    "                     'blue',\n",
    "                     'nir'],\n",
    "    'resolution': (-30, 30),\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# find the right crs for the location\n",
    "crs = mostcommon_crs(dc=dc, product='ls8_sr', query=query)\n",
    "\n",
    "# load cloud-masked fractional cover using load_ard\n",
    "ds = load_ard(dc=dc,\n",
    "              **query,\n",
    "              products=['ls8_sr'],\n",
    "              align=(15, 15),\n",
    "              output_crs=crs,\n",
    "              min_gooddata=0.7\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
